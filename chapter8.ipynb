{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数值预测的含义\n",
    "\n",
    "在上一章节，我们接触到的决策树，比较适合对数据的分类进行预测，以及我们之前学过的分类器也是如此。但是当我们对数值型结果进行预测的时候应该怎么办呢？\n",
    "具体什么叫做对数值型结果进行预测首先需要明确一下。比如：我们要在拍卖行竞价购买一个笔记本电脑，这台笔记本电脑有一些参数：处理器的速度，RAM的容量，硬盘的大小，屏幕的分辨率以及其他因素。显然，我们最终对其的定价必然要考虑这些参数，而这些参数的重要性各不相同，比如硬盘大小与屏幕大小相比，可能大家都觉得屏幕大小更为重要。那么各个因素都影响着我们最终对该款笔记本的最终的定价，这个定价就是我们所说的对数值型结果进行预测。我们可以使用第五章研究过的优化技术，求出最佳的权重。书中提出：\n",
    "\n",
    "    贝叶斯分类器\n",
    "    决策树\n",
    "    支持向量机\n",
    "\n",
    "都不是应对这种情况的最佳算法。本章将会研究如何应对这样的情况。\n",
    "\n",
    "\n",
    "构建数据集\n",
    "\n",
    "理解我们的要做什么之后，首先要做的就是数据集的问题，这次很数据集的来源很不一样，是我们自己构建的。\n",
    "在我们构建数据集的时候，不得不注意这个数据集必须具有某些特征（也即是处理器速度、硬盘大小），而且这些特征最好比较复杂，使得价格比较难以预测。比如如果对电视机进行价格的预测，很显然屏幕越大，价格越高，那么这个预测实在是太简单了。\n",
    "本书提出，构建的是一个葡萄酒价格的数据集。首先需要明确，酒的价格由两点决定，\n",
    "\n",
    "    等级\n",
    "    储藏的年代\n",
    "\n",
    "此外，葡萄酒还有“峰值年”这样一种说法，简单说来不同等级的酒，都会到了一个年份，到了该年份酒的价格是最高的，而接近这个年份的时候价格会增加，过了这个年份价格会逐渐降低。\n",
    "请看代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random,randint\n",
    "import math\n",
    "#rating代表酒的等级，age代表酒的年代\n",
    "#如果rating是代表酒的等级，同一等级的酒的峰值年是一样的。     \n",
    "#所以每一个峰值年是针对同一类等级的酒而言\n",
    "def wineprice(rating,age):    \n",
    "    peak_age = rating - 50 \n",
    "    \n",
    "    #根据等级来计算价格\n",
    "    price = rating/2\n",
    "    if age>peak_age:\n",
    "        #经过“峰值年”之后，之后的5年，酒的品质会变差，价格降低\n",
    "        price = price * (5-(age-peak_age))\n",
    "        \n",
    "    else:\n",
    "        #价格在接近“峰值年”时，会增加到原值的五倍\n",
    "        price = price*(5*((age+1)/peak_age))\n",
    "    if price < 0: price=0\n",
    "    return price\n",
    "\n",
    "def wineset1():\n",
    "    rows = []\n",
    "    for i in range(300):\n",
    "        #随机产生年代和等级\n",
    "        rating = random()*50+50\n",
    "        age = random()*50\n",
    "        \n",
    "        #得到一个参考价格 \n",
    "        price = wineprice(rating,age)\n",
    "        \n",
    "        #增加“噪声”，也就是让酒的价格随机波动一下\n",
    "        price*=(random()*0.4+0.8) #这个写法很高端\n",
    "        \n",
    "        #加入到数据集中\n",
    "        rows.append({'input':(rating,age),\n",
    "                        'result':price})\n",
    "        return rows  \n",
    "\n",
    "\n",
    "#用欧几里得来计算两瓶酒的相似度\n",
    "def euclidean(v1,v2):\n",
    "    d = 0.0\n",
    "    for i in range(len(v1)):\n",
    "        d += (v1[i] - v2[i])**2\n",
    "    return math.sqrt(d)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行代码，同一年等级的酒，不同的age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55,8): 55.0\n",
      "(55,9): 27.5\n"
     ]
    }
   ],
   "source": [
    "print ('(55,8):',wineprice(55,8))\n",
    "print ('(55,9):',wineprice(55,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，对于等级55的酒来说，峰值年为5，所以对于两个过了峰值年的酒来说，第9年显然比第8年更便宜。\n",
    "接着，我们来用代码产生葡萄酒价格的数据集，代码会随机产生200个普通酒的价格和年份，并且计算出其价格，然后随机加减20%，可以理解为是税收和价格的变动。\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wineset1():\n",
    "    rows = []\n",
    "    for i in range(300):\n",
    "        #随机产生年代和等级\n",
    "        rating = random()*50+50\n",
    "        age = random()*50\n",
    "        \n",
    "        #得到一个参考价格 \n",
    "        price = wineprice(rating,age)\n",
    "        \n",
    "        #增加“噪声”，也就是让酒的价格随机波动一下\n",
    "        price*=(random()*0.4+0.8) #这个写法很高端\n",
    "        \n",
    "        #加入到数据集中\n",
    "        rows.append({'input':(rating,age),\n",
    "                        'result':price})\n",
    "    return rows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.111111111111114"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineprice(95,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineprice(95,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.102040816326529"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineprice(99,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = wineset1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': (61.34411098690677, 6.246561129309258), 'result': 89.32909526226072}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': (58.14307938173174, 21.401432710781), 'result': 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了数据集之后，我们就研究如何对一瓶新的普通酒进行价格预测。虽然，我们在构建数据集的时候使用了一个函数来计算出价格，我们心里也知道这个价格也许是虚构的，但是，现在请将数据集里产生的价格认为是真实的，这样，我们才能对一瓶新的普通酒进行价格预测，而不是直接用之前的函数wineprice（）算出价格。\n",
    "\n",
    "k-最近邻算法\n",
    "\n",
    "这个算法思想来自于一个简单的事实：我们会找到和新普通酒相似的酒，然后看看这个相似酒的价格，再推算我们新酒的价格。所以，该算法会寻找一组与新普通酒相似的酒，求出这些价格的均值，做出价格预测。这样方法就是k-nearest nerghbors，kNNE：k-最近邻算法。\n",
    "上面一组，就代表了几个与新酒相似度的酒，这也是k的含义。那么到底选几个呢？这是值得探究的问题，显然选少了或者选多了都不是不行的。我们在实际运用时可以多试试不同的k值，也许会得到更为准确的结果。\n",
    "如何确定两瓶酒相似呢？这里我们使用了应该是比较简单的算法：欧几里得算法\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用欧几里得来计算两瓶酒的相似度\n",
    "def euclidean(v1,v2):\n",
    "    d = 0.0\n",
    "    for i in range(len(v1)):\n",
    "        d += (v1[i] - v2[i])**2\n",
    "    return math.sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': (69.23773040631832, 15.127324831115342), 'result': 145.92963650364862}\n",
      "{'input': (87.1562786489632, 22.91779374092223), 'result': 167.53160082354157}\n",
      "19.53882742025886\n"
     ]
    }
   ],
   "source": [
    "rows=wineset1()\n",
    "print (rows[0])\n",
    "print (rows[1])\n",
    "print (euclidean(rows[0]['input'],rows[1]['input']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了相似度计算公式之后，我们很容易就能够计算出两瓶酒的相似度了，下面的代码是用于计算需要预测的新酒和数据集中的每一个的酒的距离（也就是相似度），算出来之后，我们才能排序，抽取出其中k个最相似度。注意，该函数的计算量比较大。\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#得到需要预测的新酒与数据集中所有酒的相似度\n",
    "def getdistances(data,vec1):\n",
    "    distancelist = []\n",
    "    for i in range(len(data)):\n",
    "        vec2 = data[i]['input']\n",
    "        distancelist.append((euclidean(vec1,vec2),i))\n",
    "    distancelist.sort()\n",
    "    return distancelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿到了新酒与所有酒的相似度，我们取出最相似的k个，算出这个k个酒的平均值，我们就得到了对新酒预测的价格："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knnestimate(data,vec1,k=5):\n",
    "    #得到排序过后的相似度排序\n",
    "    dist = getdistances(data,vec1)\n",
    "    avg = 0.0\n",
    "    #对前k项结果求平均值\n",
    "    for i in range(k):\n",
    "        idx = dist[i][1] #这里地方之所以是1的原因是取出在data列表里的序号\n",
    "        avg += data[idx]['result']\n",
    "    avg = avg/k\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.98100614552323"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnestimate(data,(95.0,3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的结果是使用了默认的k为5，那么不同的k，产生的结果肯定也是不一样的。\n",
    "\n",
    "最相近的酒应该占有最大的比重\n",
    "\n",
    "我们发现一个问题，就是当我们的k为5的时候，相似的五瓶酒在求出最后新酒的平均值的时候占的比重是一样的，我们需要，越相近的酒占的比重应该更大，这样结果才准确。\n",
    "\n",
    "所以，我们要将得到相似度转化为权重。书中介绍了集中方式来完成这个功能：\n",
    "\n",
    "\n",
    "inverse function\n",
    "\n",
    "\n",
    "书中对这个词的翻译应该有错，书上想讲的是y=1/x的这样的函数，却翻译为了反函数。\n",
    "使用inverse function就可以完成将距离转换为权重这个过程。因为用欧几里得算出来的是两个点之间的距离，如果距离越大，那么其倒数就越小，如果距离越近，那么其倒数越大。这个方法有一个特点，就是如果非常近的话，那么占的权重非常之大，以至于会忽略掉相距稍稍有一点远的邻居，而且相距有点点远，但是它所在占的比重会下降的非常快。这到底是好事还是坏事，要看具体的项目有什么要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用倒数来将距离转为权重\n",
    "#const的存在是为了防止两点非常近，而导致了其距离非常近，倒数特别大，大到其他数都不起作用\n",
    "def inverseweight(dist,num=1.0,const=0.1):\n",
    "    return num/(dist + const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "减法函数\n",
    "\n",
    "我们也可以使用减法函数来完成将距离转化为权重。思路也非常简单，用一个固定的数去减去距离，如果距离越大，那么返回数就越小，如果距离大过某个程度，那么就返回0了。这个办法的坏处就是，当大多数邻居的距离都比较大的时候，如果都返回了0，就会导致数据不足，就没办法预测了。\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用减法函数将距离转化为权重\n",
    "def subtractweight(dist,const=1.0):\n",
    "    if dist > const:\n",
    "        return 0\n",
    "    else:\n",
    "        return const - dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯函数\n",
    "\n",
    "高斯函数也是将距离转化为权重的方法。思路涉及原理，也就是正态分布“钟形曲线”，这就不讲解了，说白了也是带入公式而已。但是高斯函数克服了上述缺点，比如权重是始终不会跌至0的。看下图，高斯函数的图形就会明白了，x轴为距离，y轴为比重：\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(dist,sigma=10.0):\n",
    "    return math.e**(-dist**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "0.9\n",
      "0.9999500012499791\n"
     ]
    }
   ],
   "source": [
    "print (inverseweight(0.1))\n",
    "print (subtractweight(0.1))\n",
    "print (gaussian(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "0.0\n",
      "0.9950124791926823\n"
     ]
    }
   ],
   "source": [
    "print (inverseweight(1))\n",
    "print (subtractweight(1))\n",
    "print (gaussian(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试三个函数的执行代码看看三者之间的差异"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加权kNN\n",
    "\n",
    "实际上没什么复杂了，和之前推荐的内容类似。刚刚我们的kNN求的是平均，这次我们就是要求加权平均。也就是通过每一项的值乘以权重，然后将结果累加而得到的。总和再除以权重之和即可。\n",
    "代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedknn(data,vec1,k=5,weightf=gaussian):\n",
    "    #得到距离值\n",
    "    dlist=getdistances(data,vec1)\n",
    "    avg = 0.0\n",
    "    totalweight = 0.0\n",
    "    \n",
    "    #得到加权平均值\n",
    "    for i in range(k):\n",
    "        dist = dlist[i][0]\n",
    "        idx = dlist[i][1]\n",
    "        weight = weightf(dist)\n",
    "        avg += weight*data[idx]['result']\n",
    "        totalweight += weight\n",
    "    avg = avg/totalweight\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.595451463064162"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightedknn(data,(99.0,5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.494485701165587"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnestimate(data,(99.0,5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉验证\n",
    "\n",
    "英文为：Cross-validation。这项技术将数据集拆分为训练集和测试集（都带有正确的答案），然后我们用训练集去训练模型，该训练集应该是带有正确答案的，然后我们再将测试集的输入传入算法，得到输出。将输出与正确的答案进行比对，看输出与正确的答案差距有多少。这里是我个人的理解，书中的描述我认为是有点错误哈。拆分一般都9比1的方式来拆分，显然训练集需要多一些。\n",
    "这样有什么好处？就是验证我们的算法是否能够准确预测，而且我们可以对比使用不同的参数产生的结果，比如k的数量，比如到底是使用减法函数还是高斯函数来做距离转化为权重。\n",
    "但是，我们这里并不是拿训练集去算法模型，而且用训练集去产生测试集中的一个预测的结果，比如knnestimate(data,vec1,k=5) 函数，其中的data传入的就是我们的训练集，vec1就是测试集中的一个。这是这一次算法的需要，但是我认为本质上还是没变的。\n",
    "首先是把一个数据集划分为2个数据集，一个训练集和一个测试集，需要95%的训练集，5%的测试集。\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将数据拆分为训练集和测试集\n",
    "def dividedata(data,test=0.05):\n",
    "    trainset = []\n",
    "    testset = []\n",
    "    for row in data:\n",
    "        if random() < test:\n",
    "            testset.append(row)\n",
    "        else:\n",
    "            trainset.append(row)\n",
    "    return trainset,testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们去测试算法，会得到产生对算法预测的误差。注意，本函数中，我们统计了是差值的平方，而不是单纯的差值。两者各有好处。\n",
    "如果我们想突显偶尔出现一次很大的差距，使用差值的平方\n",
    "如果我们关心每次与正确值的差距，而偶尔有一次很大的差距也无所谓，那么使用差值绝对值相加\n",
    "测试算法的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#测试算法的误差\n",
    "#而是直接将训练集传入knnestimate函数，作为产生一个预测结果的基础，然后算出预测结果和真实结果之间的差距\n",
    "def testalgorithm(algf,trainset,testset):\n",
    "    error = 0.0\n",
    "    for row in testset:#这里只是拿testset来做个循环\n",
    "        guess = algf(trainset,row['input'])\n",
    "        error += (row['result']-guess)**2 #对数字求平方这样会突显其差距。\n",
    "    return error/len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉测试的控制代码，从代码中，我们看出来了，并不是只做了一次拆分数据集和测试数据集代码的工作，我们是重复了100次，然后再取平均值。\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossvalidate(algf,data,trials=100,test=0.05): \n",
    "    error=0.0 \n",
    "    for i in range(trials):\n",
    "        trainset,testset=dividedata(data,test)\n",
    "        error+=testalgorithm(algf,trainset,testset)\n",
    "    return error/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430.2308244143351"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidate(knnestimate,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn3(d,v):\n",
    "    return knnestimate(d,v,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481.1702480611702"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidate(knn3,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn5(d,v):\n",
    "    return knnestimate(d,v,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488.8274665467399"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidate(knn5,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ================================ RESTART ================================ >>>  k=3时算法的误差： 534.299703506 k=3时算法的误差： 422.359768538 k=3时算法的误差： 460.892823922 k=3时算法的误差： 561.394791352 k=3时算法的误差： 438.566549999 >>> ================================ RESTART ================================ >>>  k=5时算法的误差： 356.420358448 k=5时算法的误差： 371.83561953 k=5时算法的误差： 299.178929108 k=5时算法的误差： 391.072240086 k=5时算法的误差： 352.400721703 >>> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现k=5时，误差要低很多，所以觉得k=5不错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
